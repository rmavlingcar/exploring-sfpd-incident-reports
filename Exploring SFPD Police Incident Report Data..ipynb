{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring SFPD Police Incident Report Data\n",
    "The dataset available has SFPD police incident report data from January 2003 to May 2018. The goal is to perform analysis on the available data to discern trends over the years in San Francisco's crime scene.\n",
    "\n",
    "The data is freely available at [datasf.org](https://data.sfgov.org/Public-Safety/Police-Department-Incident-Reports-Historical-2003/tmnf-yvry).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing as prepro\n",
    "import folium\n",
    "from folium.plugins import HeatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from csv file\n",
    "data = pd.read_csv(\"./data/SFPD-Incident-Reports-Jan2003-May2018.csv\")\n",
    "\n",
    "#preview rows,cols\n",
    "#print(data.shape)\n",
    "data.info()\n",
    "\n",
    "#preview data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 35 columns but we definitely don't need them all. It also looks like there may be null values throughout the dataset. Of particular interest is the Date and Time columns which we can use for temporal analysis. We also need to check for nulls and duplicates and drop them from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets read the csv data again but this time parse the date and time columns as datetime\n",
    "data = pd.read_csv(\"./data/SFPD-Incident-Reports-Jan2003-May2018.csv\", parse_dates=[['Date','Time']])\n",
    "\n",
    "#we don't need all 35 columns, so lets select what we determine to be relevant\n",
    "data = data[[\"Date_Time\",\"Category\",\"Descript\",'DayOfWeek',\"PdDistrict\",\"Resolution\",\"Address\",\"X\",\"Y\"]]\n",
    "\n",
    "#preview rows,cols\n",
    "data.info()\n",
    "\n",
    "#preview data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for nulls\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop nulls\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check how many duplicate entries there are\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicate entries\n",
    "data.drop_duplicates(subset=None, keep=\"first\", inplace=True)\n",
    "\n",
    "#preview rows,cols\n",
    "data.info()\n",
    "\n",
    "#preview data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can infer from the number of rows that there are 2,129,525 number of crimes in the dataset. Of which around 5,520 were duplicates and one had a null value leaving a total of 2,124,004 crimes.\n",
    "\n",
    "We also have temporal data in the dataset that we can format better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can breakdown the Date_Time column to split data by year, month and day. Note that we only have 2018 data from Jan to May so we are going to drop 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Year'] = pd.DatetimeIndex(data['Date_Time']).year\n",
    "data['Month'] = pd.DatetimeIndex(data['Date_Time']).month\n",
    "data['Day'] = pd.DatetimeIndex(data['Date_Time']).day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['Year'] != 2018]\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After dropping the 2018 year data, we are left with 2,079,049 incident reports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've cleaned up this data enough to finally start some exploratory data analysis.\n",
    "\n",
    "We can visualise the data with a correlation heatmap for all our features in the dataset but we would have to first encode our categorical features (PdDistrict, Category, Address,etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of the data\n",
    "data_enc = data.copy()\n",
    "\n",
    "# label encoding\n",
    "for i in ['Category','Descript','DayOfWeek','PdDistrict','Resolution','Address']:\n",
    "    data_enc[i] = prepro.LabelEncoder().fit_transform(data_enc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation matrix\n",
    "corr_mat = data_enc.corr()\n",
    "corr_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "sns.heatmap(corr_mat, annot=True, linewidths=.1)\n",
    "plt.title('Heatmap for dataset', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can determine the different categories of crimes and number of crimes in each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_crimes_cat = data[\"Category\"].value_counts()\n",
    "print(num_crimes_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the most prevalent type of crime from 2003 to 2018 is larceny/theft. We can plot a bar chart to visualise the data here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "num_crimes_cat.plot(kind='bar',xlabel='Category',ylabel='Occurences',title='Crime occurences by category',figsize=(16,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check which day has the highest number of crimes committed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_days = data[\"DayOfWeek\"].value_counts()\n",
    "crime_days.plot(kind='bar',xlabel='Day',ylabel='Occurences',title='Crime occurences by day of the week',figsize=(10,10),width=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the descriptions and see what is the most prevalent as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = data[\"Descript\"].value_counts()\n",
    "# limit to top 20 due to volume of descriptions\n",
    "desc[:20].plot(kind='bar',xlabel='Description',ylabel='Occurences',title='Crime occurences vs Description', figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PdDistricts column can give us an idea of which neighbourhoods we may want to avoid in SF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "data['PdDistrict'].value_counts().plot(kind='bar',xlabel='District',ylabel='Occurences',title='Crime occurences in each District', figsize=(10,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_data = data['Year'].value_counts().sort_index()\n",
    "years_data.plot(kind='bar',xlabel='Year',ylabel='Occurences',title='Crime occurences per year', figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to find out about a specific category of crime being committed over the years. We can now do so since we processed the year information earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_theft_df = data[data['Category'] == 'VEHICLE THEFT']\n",
    "yearly_vehicle_theft = vehicle_theft_df.groupby('Year').Date_Time.nunique()\n",
    "plt.figure()\n",
    "yearly_vehicle_theft.plot(kind='bar',xlabel='Year', ylabel='Occurences of Vehicle Theft', title='Number of Vehicle Thefts per year',figsize=(16,9))\n",
    "plt.show()\n",
    "# vehicle_theft_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vandalism_df = data[data['Category'] == 'VANDALISM']\n",
    "yearly_vandalism = vandalism_df.groupby('Year').Date_Time.nunique()\n",
    "plt.figure()\n",
    "yearly_vandalism.plot(kind='bar',xlabel='Year', ylabel='Occurences of Vandalism', title='Number of Vandalism reports per year',figsize=(16,9))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the incident report geo coordinate data to generate a heatmap that visualises where most crimes are reported in the city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df = data.copy()\n",
    "sample_data = data.sample(int(0.1 * len(geo_df)))\n",
    "X_Y_pairs = list(zip(list(sample_data.Y), list(sample_data.X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = folium.Map(location=[37.733795, -122.446747],zoom_start=12)\n",
    "HeatMap(X_Y_pairs).add_to(map)\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
